
# Audio device configuration (verified from arecord/aplay -l)
audio:
  sample_rate: 16000           # Whisper and Porcupine both use 16kHz
  channels: 1                  # Mono audio
  chunk_size: 512              # Porcupine frame length
  format: "int16"              # 16-bit signed integer
  input_device_index: 4        # Use 'default' (Index 4 according to latest scan)
  output_device_index: 4       # Use 'default' (Index 4 according to latest scan)

# Porcupine wake word configuration
wake_word:
  access_key: "${PORCUPINE_ACCESS_KEY}"  # Will be loaded from .env
  keyword: "computer"          # Options: computer, jarvis, alexa, etc.
  sensitivity: 0.5             # Range: 0.0-1.0 (higher = more sensitive)
  
# Speech-to-Text configuration
stt:
  model: "tiny.en"             # Options: tiny.en, base.en, small.en
  device: "cpu"                # Pi 4 uses CPU
  compute_type: "int8"         # int8 for speed, float16 for accuracy
  language: "en"               # English
  OPTIMIZED_MODE: 1            # 1: Enable Pi 4 optimizations, 0: Standard mode
  beam_size: 5                 # Standard beam size (will be 1 if OPTIMIZED_MODE is 1)
  
# Groq LLM configuration
llm:
  api_key: "${GROQ_API_KEY}"           # Will be loaded from .env
  model: "llama-3.3-70b-versatile"
  temperature: 0.7
  max_tokens: 150
  max_history: 5                 # Number of past exchanges to keep for context
  system_prompt: |
    You are an expressive and helpful voice assistant. Provide natural, conversational responses in 1-2 sentences. 
    Avoid one-word answers. Keep it under 50 words.
    
    Choose an appropriate "mood" for your response based on the context:
    - happy: for friendly, positive, or funny responses.
    - sad: if the user reveals bad news or the topic is gloomy.
    - excited: for high-energy, enthusiastic, or surprising news.
    - thinking: when explaining a complex concept or "pondering" a deep question.
    - curious: when the user asks a "how/why" question or you want to show interest.
    - angry: when the user is being rude or the topic is frustrating.
    - proud: when you or the user achieves something great.
    - neutral: only if none of the above apply. Be expressive!
    
    CRITICAL: You MUST respond with ONLY a valid JSON object in this exact format:
    {
      "response": "your actual response text here",
      "mood": "chosen_mood"
    }
    
    Do NOT include any text before or after the JSON. Do NOT use markdown code blocks. ONLY output raw JSON.
  
# OLED display configuration (verified with i2cdetect)
display:
  type: "ssd1306"              # Controller type (NOT sh1106)
  width: 128                   # Screen width
  height: 64                   # Screen height
  i2c_bus: 1                   # IÂ²C bus number
  i2c_address: 0x3C            # Hexadecimal address (verified)
  contrast: 255                # Max brightness (0-255)
  mood_duration: 10.0          # How long (seconds) to play mood animation after response

# Text-to-Speech configuration
tts:
  engine: "sherpa-onnx"          # "sherpa-onnx" or "espeak-ng"
  model_path: "models/tts/vits-piper-en_US-lessac-medium"
  num_threads: 2               # CPU threads for inference
  speed: 1.0                   # Speech speed multiplier
  espeak_voice: "en"           # Fallback voice

# Recording behavior
recording:
  max_duration: 10.0           # Maximum recording time (seconds)
  silence_threshold: 600       # RMS threshold for silence detection
  silence_duration: 0.8        # Seconds of silence before auto-stop
  pre_buffer_duration: 0.5     # Seconds to keep before wake word

# Logging
logging:
  level: "INFO"                # DEBUG, INFO, WARNING, ERROR
  file: "logs/voice_assistant.log"
  console: true
